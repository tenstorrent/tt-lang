# SPDX-FileCopyrightText: (c) 2025 Tenstorrent AI ULC
# SPDX-License-Identifier: Apache-2.0

"""
MNIST inference using pre-compiled kernels via ttnn.generic_op.

This script uses the C++ kernels generated by tt-lang and invokes them
directly through ttnn.generic_op, bypassing the tt-lang compilation step.

The kernel paths and configurations were extracted from the runner files
generated by setting TTLANG_EMIT_RUNNER=1.
"""

import os
import torch
import numpy as np
import ttnn

# Dimensions (must match the compiled kernels)
BATCH = 32
INPUT_DIM = 800
HIDDEN_DIM = 1024
OUTPUT_DIM = 32
NUM_CHUNKS = 8
CHUNK_SIZE = 128
BATCH_TILES = 1
INPUT_TILES = 25
CHUNK_TILES = 4
OUTPUT_TILES = 1


# =============================================================================
# Layer 1: hidden = relu(X @ W1 + bias1)
# Grid: (8, 1) - 8 cores compute chunks in parallel
# Tensors: [x, w1, bias1, hidden_out]
# =============================================================================

LAYER1_GRID = (8, 1)
LAYER1_NUM_TENSORS = 4

_KERNEL_DIR = os.path.join(os.path.dirname(__file__), "kernels")

LAYER1_KERNEL_PATHS = [
    (os.path.join(_KERNEL_DIR, "layer1_compute.cpp"), "compute"),
    (os.path.join(_KERNEL_DIR, "layer1_dm_read.cpp"), "noc"),
    (os.path.join(_KERNEL_DIR, "layer1_dm_write.cpp"), "noc"),
]

# Tensor indices for common_runtime_args
# dm_read accesses: bias1(2), w1(1), x(0) in that order
# dm_write accesses: hidden_out(3)
LAYER1_TENSOR_INDICES = [
    [],        # compute
    [2, 1, 0], # dm_read
    [3],       # dm_write
]

# CB configs: (shape, buffer_factor, dtype, page_size, total_size)
LAYER1_CB_CONFIGS = [
    ((1, 25), 1, ttnn.bfloat16, 2048, 51200),   # CB 0: x_cb
    ((25, 4), 1, ttnn.bfloat16, 2048, 204800),  # CB 1: w1_cb
    ((1, 4), 1, ttnn.bfloat16, 2048, 8192),     # CB 2: bias1_cb
    ((1, 4), 2, ttnn.bfloat16, 2048, 16384),    # CB 3: hidden_mm_cb
    ((1, 4), 1, ttnn.bfloat16, 2048, 8192),     # CB 4: hidden_cb
]


def run_layer1(tensors):
    """Run Layer 1 kernel: hidden = relu(X @ W1 + bias1)"""
    assert len(tensors) == LAYER1_NUM_TENSORS

    grid_cols, grid_rows = LAYER1_GRID
    core_ranges = ttnn.CoreRangeSet([ttnn.CoreRange(
        ttnn.CoreCoord(0, 0),
        ttnn.CoreCoord(grid_cols - 1, grid_rows - 1)
    )])

    # Build tensor accessor args
    tensor_accessor_args = []
    for tensor in tensors:
        tensor_accessor_args.extend(ttnn.TensorAccessorArgs(tensor).get_compile_time_args())

    # Build CB descriptors
    cb_descriptors = []
    for i, (shape, buffer_factor, dtype, page_size, total_size) in enumerate(LAYER1_CB_CONFIGS):
        cb_format = ttnn.CBFormatDescriptor(
            buffer_index=i,
            data_format=dtype,
            page_size=page_size,
        )
        cb_desc = ttnn.CBDescriptor(
            total_size=total_size,
            core_ranges=core_ranges,
            format_descriptors=[cb_format],
        )
        cb_descriptors.append(cb_desc)

    # Build kernel descriptors
    cb_indices = list(range(len(LAYER1_CB_CONFIGS)))
    kernel_descriptors = []
    noc_idx = 0

    for kernel_idx, (kernel_path, thread_type) in enumerate(LAYER1_KERNEL_PATHS):
        tensor_indices = LAYER1_TENSOR_INDICES[kernel_idx]
        runtime_args = [[[] for _ in range(grid_rows)] for _ in range(grid_cols)]
        common_runtime_args = [tensors[idx].buffer_address() for idx in tensor_indices]

        if thread_type == 'compute':
            compile_time_args = cb_indices
            config = ttnn.ComputeConfigDescriptor()
        else:
            compile_time_args = cb_indices + tensor_accessor_args
            config = ttnn.ReaderConfigDescriptor() if noc_idx == 0 else ttnn.WriterConfigDescriptor()
            noc_idx += 1

        kernel_desc = ttnn.KernelDescriptor(
            kernel_source=kernel_path,
            core_ranges=core_ranges,
            compile_time_args=compile_time_args,
            runtime_args=runtime_args,
            common_runtime_args=common_runtime_args,
            config=config,
        )
        kernel_descriptors.append(kernel_desc)

    program = ttnn.ProgramDescriptor(
        kernels=kernel_descriptors,
        cbs=cb_descriptors,
        semaphores=[],
    )

    return ttnn.generic_op(list(tensors), program)


# =============================================================================
# Layer 2: out = softmax(sum(hidden_chunks @ W2_chunks) + bias2)
# Grid: (1, 1) - single core accumulates and computes softmax
# Tensors: [hidden, w2, bias2, scaler, out]
# =============================================================================

LAYER2_GRID = (1, 1)
LAYER2_NUM_TENSORS = 5

LAYER2_KERNEL_PATHS = [
    (os.path.join(_KERNEL_DIR, "layer2_compute.cpp"), "compute"),
    (os.path.join(_KERNEL_DIR, "layer2_dm_read.cpp"), "noc"),
    (os.path.join(_KERNEL_DIR, "layer2_dm_write.cpp"), "noc"),
]

# Tensor indices for common_runtime_args
# dm_read accesses: bias2(2), hidden(0), scaler(3), w2(1) in that order
# dm_write accesses: out(4)
LAYER2_TENSOR_INDICES = [
    [],           # compute
    [2, 0, 3, 1], # dm_read
    [4],          # dm_write
]

# CB configs for Layer 2 (13 CBs for softmax computation)
LAYER2_CB_CONFIGS = [
    ((1, 4), 2, ttnn.bfloat16, 2048, 16384),  # CB 0: hidden_cb
    ((4, 1), 2, ttnn.bfloat16, 2048, 16384),  # CB 1: w2_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 2: acc_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 3: part_cb
    ((1, 1), 1, ttnn.bfloat16, 2048, 2048),   # CB 4: bias2_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 5: logits_cb
    ((1, 1), 1, ttnn.bfloat16, 2048, 2048),   # CB 6: scaler_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 7: max_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 8: max_bcast_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 9: exp_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 10: sum_cb
    ((1, 1), 2, ttnn.bfloat16, 2048, 4096),   # CB 11: sum_bcast_cb
    ((1, 1), 1, ttnn.bfloat16, 2048, 2048),   # CB 12: out_cb
]


def run_layer2(tensors):
    """Run Layer 2 kernel: out = softmax(accumulated_matmul + bias2)"""
    assert len(tensors) == LAYER2_NUM_TENSORS

    grid_cols, grid_rows = LAYER2_GRID
    core_ranges = ttnn.CoreRangeSet([ttnn.CoreRange(
        ttnn.CoreCoord(0, 0),
        ttnn.CoreCoord(grid_cols - 1, grid_rows - 1)
    )])

    # Build tensor accessor args
    tensor_accessor_args = []
    for tensor in tensors:
        tensor_accessor_args.extend(ttnn.TensorAccessorArgs(tensor).get_compile_time_args())

    # Build CB descriptors
    cb_descriptors = []
    for i, (shape, buffer_factor, dtype, page_size, total_size) in enumerate(LAYER2_CB_CONFIGS):
        cb_format = ttnn.CBFormatDescriptor(
            buffer_index=i,
            data_format=dtype,
            page_size=page_size,
        )
        cb_desc = ttnn.CBDescriptor(
            total_size=total_size,
            core_ranges=core_ranges,
            format_descriptors=[cb_format],
        )
        cb_descriptors.append(cb_desc)

    # Build kernel descriptors
    cb_indices = list(range(len(LAYER2_CB_CONFIGS)))
    kernel_descriptors = []
    noc_idx = 0

    for kernel_idx, (kernel_path, thread_type) in enumerate(LAYER2_KERNEL_PATHS):
        tensor_indices = LAYER2_TENSOR_INDICES[kernel_idx]
        runtime_args = [[[] for _ in range(grid_rows)] for _ in range(grid_cols)]
        common_runtime_args = [tensors[idx].buffer_address() for idx in tensor_indices]

        if thread_type == 'compute':
            compile_time_args = cb_indices
            config = ttnn.ComputeConfigDescriptor()
        else:
            compile_time_args = cb_indices + tensor_accessor_args
            config = ttnn.ReaderConfigDescriptor() if noc_idx == 0 else ttnn.WriterConfigDescriptor()
            noc_idx += 1

        kernel_desc = ttnn.KernelDescriptor(
            kernel_source=kernel_path,
            core_ranges=core_ranges,
            compile_time_args=compile_time_args,
            runtime_args=runtime_args,
            common_runtime_args=common_runtime_args,
            config=config,
        )
        kernel_descriptors.append(kernel_desc)

    program = ttnn.ProgramDescriptor(
        kernels=kernel_descriptors,
        cbs=cb_descriptors,
        semaphores=[],
    )

    return ttnn.generic_op(list(tensors), program)


# =============================================================================
# Main inference logic
# =============================================================================

def to_ttnn(t, device):
    """Convert torch tensor to ttnn tensor on device."""
    return ttnn.from_torch(
        t, dtype=ttnn.bfloat16, layout=ttnn.TILE_LAYOUT,
        device=device, memory_config=ttnn.DRAM_MEMORY_CONFIG
    )


def main():
    base = "/home/zcarver.linux"

    # Load weights
    weights = torch.load(f"{base}/mnist_weights.pt", weights_only=True)
    w1_orig, b1_orig, w2_orig, b2_orig = weights['w1'], weights['b1'], weights['w2'], weights['b2']

    # Pad weights to tile-aligned dimensions
    w1 = torch.zeros(INPUT_DIM, HIDDEN_DIM, dtype=torch.bfloat16)
    w1[:784, :] = w1_orig.to(torch.bfloat16)
    b1 = b1_orig.unsqueeze(0).expand(BATCH, -1).contiguous().to(torch.bfloat16)
    w2 = torch.zeros(HIDDEN_DIM, OUTPUT_DIM, dtype=torch.bfloat16)
    w2[:, :10] = w2_orig.to(torch.bfloat16)
    b2_full = torch.zeros(OUTPUT_DIM, dtype=torch.bfloat16)
    b2_full[:10] = b2_orig.to(torch.bfloat16)
    b2 = b2_full.unsqueeze(0).expand(BATCH, -1).contiguous()

    # Load test data
    X_test = np.fromfile(f"{base}/data/X_test.bin", dtype=np.float32).reshape(-1, 784)
    y_test = np.fromfile(f"{base}/data/y_test.bin", dtype=np.int32)
    X_test = (X_test - 0.1307) / 0.3081  # Normalize

    print("=== MNIST Inference via ttnn.generic_op ===")
    print("Using pre-compiled tt-lang kernels directly")
    print()

    device = ttnn.open_device(device_id=0)

    # Allocate buffers
    scaler = torch.ones(32, 32, dtype=torch.bfloat16)
    hidden_buf = torch.zeros(BATCH, HIDDEN_DIM, dtype=torch.bfloat16)
    out_buf = torch.zeros(BATCH, OUTPUT_DIM, dtype=torch.bfloat16)

    # Convert weights to TTNN (only once)
    w1_tt = to_ttnn(w1, device)
    b1_tt = to_ttnn(b1, device)
    w2_tt = to_ttnn(w2, device)
    b2_tt = to_ttnn(b2, device)
    scaler_tt = to_ttnn(scaler, device)

    correct, total = 0, 0
    num_batches = 10

    for i in range(num_batches):
        # Pad input
        x_np = X_test[i*BATCH:(i+1)*BATCH]
        x = torch.zeros(BATCH, INPUT_DIM, dtype=torch.bfloat16)
        x[:, :784] = torch.from_numpy(x_np).to(torch.bfloat16)

        x_tt = to_ttnn(x, device)
        hidden_tt = to_ttnn(hidden_buf, device)
        out_tt = to_ttnn(out_buf, device)

        # Run Layer 1: hidden = relu(X @ W1 + bias1)
        # Tensors order: [x, w1, bias1, hidden_out]
        run_layer1([x_tt, w1_tt, b1_tt, hidden_tt])

        # Run Layer 2: out = softmax(hidden @ W2 + bias2)
        # Tensors order: [hidden, w2, bias2, scaler, out]
        run_layer2([hidden_tt, w2_tt, b2_tt, scaler_tt, out_tt])

        # Get predictions
        result = ttnn.to_torch(out_tt).float()[:, :10]
        preds = result.argmax(dim=1).numpy()
        labels = y_test[i*BATCH:(i+1)*BATCH]

        correct += (preds == labels).sum()
        total += BATCH

        if i == 0:
            print(f"Predictions: {preds[:8]}")
            print(f"Labels:      {labels[:8]}")

    print(f"\nAccuracy: {100*correct/total:.2f}% ({correct}/{total})")
    ttnn.close_device(device)


if __name__ == "__main__":
    main()
